# LLMPapers

LLM: Large Language Model

## [Content](#content)

<table>
<tr><td colspan="2"><a href="#survey-papers">1. Survey</a></td></tr> 
<tr><td colspan="2"><a href="#fundamental-papers">2. Fundamental Papers</a></td></tr> 
<tr><td colspan="2"><a href="#methods">3. Methods</a></td></tr>
<tr>
    <td>&emsp;<a href="#in-context learning">3.1 In-context Learning</a></td>
    <td></td>
</tr>
<tr><td colspan="2"><a href="#fine-tuning">4. Fine-tuning</a></td></tr>
<tr>
    <td>&emsp;<a href="#post-ft">4.1 Post FT</a></td>
    <td></td>
</tr>
<tr><td colspan="2"><a href="#quantization">5. Quantization</a></td></tr>
<tr><td colspan="2"><a href="#applications">6. Applications</a></td></tr> 
<tr>
    <td>&emsp;<a href="#qa">6.1 QA</a></td>
    <td>&emsp;<a href="#rag">6.2 RAG</a></td>
</tr>
<tr><td colspan="2"><a href="#cool-ideas">7. Cool Ideas</a></td></tr>
<tr><td colspan="2"><a href="#llm-explainability">8. LLM Explainability</a></td></tr>
<tr>
    <td></td>
    <td></td>
</tr>
<tr><td colspan="2"><a href="#useful-notebooks and repos">9. Useful Notebooks and Repos</a></td></tr>
</table>

## [Survey papers](#content)


## [Fundamental papers](#content)
1. **Attention is all you need.** NeuIPS 2017. [paper](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

    *Vaswani, Ashish, et al.*

1. **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** arXiv, 2023. [paper](https://arxiv.org/pdf/2201.11903.pdf)

	*Jason Wei, et al.*

   
## [Methods](#content)   

### [In-context Learning](#content)
1. **In-Context Learning Creates Task Vectors.** arXiv, 2023. [paper](https://arxiv.org/pdf/2310.15916.pdf)

   *Hendel, Roee, Mor Geva, and Amir Globerson.*
   
1. **Iterative Forward Tuning Boosts In-context Learning in Language Models** arXiv, 2023. [paper](https://arxiv.org/pdf/2305.13016.pdf)

   *Yang, Jiaxi, et al.*

1. **In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering** arXiv, 2023. [paper](https://arxiv.org/abs/2311.06668)

	*Sheng L., et al.*

## [Fine-tuning](#content) 
1.  **How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition.** arXiv, 2023. [paper](https://arxiv.org/pdf/2310.05492.pdf)
	
 	*Dong, G., et al.*


### [Post FT](#content) 

1. **Direct Preference Optimization: Your Language Model is Secretly a Reward
  Model.** arXiv, 2023. [paper](https://arxiv.org/pdf/2305.18290.pdf)

    *Rafailov, R., et al.*

1. **Safer-Instruct: Aligning Language Models with Automated Preference Data** arXiv, 2023. [Paper](https://arxiv.org/pdf/2311.08685.pdf) [Code](https://github.com/uscnlp-lime/safer-instruct)

   *Taiwei Shi, et al.*


## [Quantization](#content)  
1. **LongLLMLingua: ACCELERATING AND ENHANCING LLMS IN LONG CONTEXT SCENARIOS VIA PROMPT COMPRESSION** EMNLP, 2023. [paper](https://arxiv.org/pdf/2310.06839.pdf) [Code](https://github.com/microsoft/LLMLingua)

## [Applications](#content)  

### [QA](#content)
1. **Merging Generated and Retrieved Knowledge for Open-Domain QA.** arXiv, 2023. [paper](https://arxiv.org/pdf/2310.14393.pdf)

   *Zhang, Y., et al. *

### [RAG](#content)
1. **LammaIndex**. [Tweet](https://x.com/jerryjliu0/status/1724837344543695185?s=20) [Code](https://github.com/run-llama/llama_index)
1. **RAG Problems** [Tweet](https://x.com/IntuitMachine/status/1724811179418079242?s=20)
1. **RAG Future** [Tweet](https://x.com/CShorten30/status/1724443501146902876?s=20) [video](https://t.co/qVaLmYg8D4)
1. **ARES: An Automatic Evaluation Framework for Retrieval-Augmented Generation (RAG)** arXiv, 2023. [Tweet](https://x.com/JonSaadFalcon/status/1724998954402935061?s=20) [Paper](https://arxiv.org/pdf/2311.09476.pdf) [Code](https://github.com/stanford-futuredata/ARES/)

   *Jon Saad-Falcon, et al.*
1. **RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval** arXiv, 2024. [paper](https://arxiv.org/pdf/2401.18059.pdf)
	
 	*Parth Sarthi, et al.*

1. **Seven Failure Points When Engineering a Retrieval Augmented Generation System** arXiv, 2024. [paper](https://arxiv.org/pdf/2401.05856.pdf)
	
 	*Scott Barnett, et al.*

1. **12 RAG Pain Points and Proposed Solutions** [Medium](https://medium.com/towards-data-science/12-rag-pain-points-and-proposed-solutions-43709939a28c)
	
## [Cool Ideas](#content)  
1. **RAIN: Your Language Models Can Align Themselves without Finetuning.** arXiv, 2023. [paper](https://arxiv.org/pdf/2309.07124.pdf) [Code](https://github.com/SafeAILab/RAIN)

   *Li, Y., et al.*

1. **Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs** arXiv, 2023. [paper](https://arxiv.org/pdf/2311.02262.pdf) [Code](https://github.com/QingruZhang/PASTA)

1. **In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering** arXiv, 2023. [paper](https://arxiv.org/abs/2311.06668)

	*Sheng L., et al.*

1. **The Power of Noise: Redefining Retrieval for RAG Systems** arXiv, 2024. [paper](https://arxiv.org/pdf/2401.14887.pdf)

	*Florin Cuconasu, et al.* 

## [LLM Explainability](#content)  

## [Useful Notebooks and Repos](#content)  
1. **Fine-tuning Mistral 7B using QLoRA** [Code](https://github.com/brevdev/notebooks/blob/main/mistral-finetune.ipynb)
1. **OCR + Amazon's MistralLite for a PDF Analysis Chatbot.** [Code](https://github.com/brevdev/notebooks/blob/main/ocr-pdf-analysis.ipynb)
1. **Hallucination Leaderboard** [Code](https://github.com/vectara/hallucination-leaderboard/)
1. **LLM Guardrails/Hallucination Evaluation** [Code](https://confluence.ext.net.nokia.com/pages/viewpage.action?pageId=1578607869)
1. **Tiny-Random-llama-2** [Tweet](https://x.com/StasBekman/status/1724519457790509310?s=20) [Code](https://github.com/stas00/ml-engineering/blob/master/transformers/make-tiny-models.md) [HuggingFace](https://huggingface.co/stas/tiny-random-llama-2/blob/main/make_tiny_model.py)
1. **Alignment Handbook (Zypher)** [Code](https://github.com/huggingface/alignment-handbook)
